{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook shows how to train and evaluate PyTorch models with GluonTS \n",
    "While there are no predefined PyTorch estimators yet, you can make use of the convenient evaluation interface of GluonTS to experiment with your own PyTorch forecasting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the neural network hyperparameters\n",
    "\n",
    "prediction_length = 12\n",
    "context_length = 24\n",
    "\n",
    "hyperparams = {\"prediction_length\": prediction_length,\n",
    "               \"context_length\": context_length,\n",
    "               \"dims\": [96, 48],\n",
    "               \"batch_normalization\": True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a simple feed forward torch nerual network\n",
    "\n",
    "class SimpleTorchNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, prediction_length, context_length, dims, batch_normalization):\n",
    "        super(SimpleTorchNetwork, self).__init__()\n",
    "        self.prediction_length = prediction_length\n",
    "        self.context_length = context_length\n",
    "        \n",
    "        modules = []\n",
    "\n",
    "        for i, units in enumerate(dims):\n",
    "            if i == 0:\n",
    "                input_size = context_length\n",
    "            else:\n",
    "                input_size = dims[i-1]\n",
    "            modules += [nn.Linear(input_size, units), nn.ReLU()]\n",
    "            if batch_normalization:\n",
    "                modules.append(nn.BatchNorm1d(units))\n",
    "        \n",
    "        modules.append(nn.Linear(dims[-1], prediction_length))\n",
    "        \n",
    "        self.nn = nn.Sequential(*modules)\n",
    "        \n",
    "\n",
    "\n",
    "class SimpleTorchTrainNetwork(SimpleTorchNetwork):\n",
    "    def forward(self, past_target, future_target):\n",
    "        prediction = self.nn(past_target)\n",
    "        # calculate L1 loss with the future_target to learn the median\n",
    "        return (prediction - future_target).abs().mean(axis=-1)\n",
    "\n",
    "\n",
    "class SimpleTorchPredNetwork(SimpleTorchTrainNetwork):\n",
    "    # The prediction network only receives past_target and returns predictions\n",
    "    def forward(self, past_target):\n",
    "        prediction = self.nn(past_target)\n",
    "        return prediction.unsqueeze_(1)\n",
    "    \n",
    "    \n",
    "net = SimpleTorchTrainNetwork(**hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the input transformation\n",
    "\n",
    "from gluonts.transform import (\n",
    "    InstanceSplitter,\n",
    "    ExpectedNumInstanceSampler\n",
    ")\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "\n",
    "transformation = InstanceSplitter(\n",
    "                target_field=FieldName.TARGET,\n",
    "                is_pad_field=FieldName.IS_PAD,\n",
    "                start_field=FieldName.START,\n",
    "                forecast_start_field=FieldName.FORECAST_START,\n",
    "                train_sampler=ExpectedNumInstanceSampler(num_instances=1),\n",
    "                past_length=context_length,\n",
    "                future_length=prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating some artificial time series\n",
    "\n",
    "from gluonts.dataset.repository.datasets import get_dataset, dataset_recipes\n",
    "from gluonts.dataset.artificial import ComplexSeasonalTimeSeries\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "artificial_dataset = ComplexSeasonalTimeSeries(\n",
    "    num_series=10,\n",
    "    prediction_length=prediction_length,\n",
    "    freq_str=\"H\",\n",
    "    length_low=50,\n",
    "    length_high=200,\n",
    "    min_val=-500,\n",
    "    max_val=500,\n",
    "    is_integer=False,\n",
    "    proportion_missing_values=0,\n",
    "    is_noise=True,\n",
    "    is_scale=True,\n",
    "    percentage_unique_timestamps=1,\n",
    "    is_out_of_bounds_date=True,\n",
    ")\n",
    "train_ds = ListDataset(artificial_dataset.train,\n",
    "                        freq=artificial_dataset.metadata.freq)\n",
    "test_ds = ListDataset(artificial_dataset.test,\n",
    "                        freq=artificial_dataset.metadata.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the training data loader\n",
    "\n",
    "from gluonts.torch.batchify import batchify \n",
    "from gluonts.dataset.loader import TrainDataLoader\n",
    "\n",
    "batch_size = 32\n",
    "num_batches_per_epoch = 300\n",
    "\n",
    "data_loader = TrainDataLoader(train_ds, batch_size=batch_size, stack_fn=batchify,\n",
    "                              transform=transformation,\n",
    "                              num_batches_per_epoch=num_batches_per_epoch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# writing a custom training loop\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "num_workers = 4\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-8\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "            net.parameters(), lr=learning_rate\n",
    "        )\n",
    "\n",
    "\n",
    "for epoch_no in range(epochs):\n",
    "    \n",
    "    # mark epoch start time\n",
    "    tic = time.time()\n",
    "    avg_epoch_loss = 0.0\n",
    "\n",
    "    with tqdm(data_loader) as it:\n",
    "        for batch_no, data_entry in enumerate(it, start=1):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            inputs = torch.Tensor(data_entry[\"past_target\"])\n",
    "            targets = torch.Tensor(data_entry[\"future_target\"])\n",
    "                    \n",
    "            loss = torch.mean(net(inputs, targets))\n",
    "            avg_epoch_loss += loss.data.numpy().item()\n",
    "            it.set_postfix(\n",
    "                ordered_dict={\n",
    "                    \"avg_epoch_loss\": avg_epoch_loss / batch_no,\n",
    "                    \"epoch\": epoch_no,\n",
    "                },\n",
    "                refresh=False,\n",
    "            )\n",
    "            n_iter = epoch_no*num_batches_per_epoch + batch_no\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "        # mark epoch end time and log time cost of current epoch\n",
    "        toc = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the prediction network and copy the parameter from the train network\n",
    "\n",
    "from gluonts.torch.support.util import copy_parameters\n",
    "pred_net = SimpleTorchPredNetwork(**hyperparams)\n",
    "copy_parameters(net, pred_net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model using a predictor\n",
    "\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator\n",
    "import json\n",
    "from gluonts.torch.model.predictor import PyTorchPredictor\n",
    "\n",
    "predictor = PyTorchPredictor(prediction_length=prediction_length, freq = artificial_dataset.metadata.freq, \n",
    "                             input_names = [\"past_target\"], prediction_net=pred_net, batch_size=32, input_transform=transformation,\n",
    "                device=None)\n",
    "\n",
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_ds,  # test dataset\n",
    "    predictor=predictor,  # predictor\n",
    "    num_samples=4000,  # number of sample paths we want for evaluation\n",
    ")\n",
    "\n",
    "forecasts = list(forecast_it)\n",
    "tss = list(ts_it)\n",
    "           \n",
    "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n",
    "print(json.dumps(agg_metrics, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting some forecasts\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_ds,  \n",
    "    predictor=predictor,\n",
    "    num_samples=1 # note: in this example we do not do probabilistic forecasting\n",
    ")\n",
    "\n",
    "for i, (prediction, target) in enumerate(zip(forecast_it, ts_it)):\n",
    "    plt.plot(target[len(target)//3:], label=\"target\")\n",
    "    plt.plot(target.index[-prediction_length:], prediction.samples[0], label=\"prediction\")\n",
    "    plt.xticks(rotation=60)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if i ==3:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
